-- glslfx version 0.1

//
// Copyright 2019 Pixar
//
// Licensed under the terms set forth in the LICENSE.txt file available at
// https://openusd.org/license.
//

-- configuration
{
    "techniques": {
        "default": {
            "domeLightCubemap": {
                "source": [ "DomeLight.Common",
                            "DomeLight.Cubemap" ]
            },
            "domeLightIrradiance": {
                "source": [ "DomeLight.Common",
                            "DomeLight.Irradiance" ]
            },
            "domeLightPrefilter": {
                "source": [ "DomeLight.Common",
                            "DomeLight.CommonSampling",
                            "DomeLight.Prefilter" ]
            },
            "domeLightBRDF": {
                "source": [ "DomeLight.Common",
                            "DomeLight.CommonSampling",
                            "DomeLight.BRDF" ]
            }
        }
    }
}

--- --------------------------------------------------------------------------
-- glsl DomeLight.Common

const float PI = 3.1415926536;

ivec3 GetCubemapCoords()
{
    // x and y coords specify texel within a face of the cubemap
    // z coord specifies the cubemap face
    //   0 -> +X, 1 -> -X, 2 -> +Y, 3 -> -Y, 4 -> +Z, 5 -> -Z
    const ivec2 invocationCoords = ivec2(hd_GlobalInvocationID.xy);
    const int outTextureWidth = HgiGetSize_outTexture().x;
    return ivec3(
        mod(invocationCoords.x, outTextureWidth),
        invocationCoords.y,
        invocationCoords.x / outTextureWidth);
}

// compute texture coords based on the size of the output image/texture
vec2 GetTexCoords(ivec2 outCoords)
{
    vec2 outDims = vec2(HgiGetSize_outTexture());
    // apply a (0.5, 0.5) offset to use pixel centers and not pixel corners
    vec2 texCoords = (vec2(outCoords) + vec2(0.5, 0.5)) / outDims;
    return texCoords;
}

vec3 GetCubemapVec(ivec3 coords)
{
    const vec2 uv = GetTexCoords(coords.xy);

    vec3 dir = vec3(0);

    // This uses the OpenGL convention for cubemaps, which is a left-handed
    // coordinate system.
    //
    // So if +X is to the right, and +Y is up, then +Z is into the screen.

    if (coords.z == 0) {
        // Positive X
        const float z = mix(1.0, -1.0, uv.x);
        const float y = mix(1.0, -1.0, uv.y);
        dir = vec3(1.0, y, z);
    } else if (coords.z == 1) {
        // Negative X
        const float z = mix(-1.0, 1.0, uv.x);
        const float y = mix(1.0, -1.0, uv.y);
        dir = vec3(-1.0, y, z);
    } else if (coords.z == 2) {
        // Positive Y
        const float x = mix(-1.0, 1.0, uv.x);
        const float z = mix(-1.0, 1.0, uv.y);
        dir = vec3(x, 1.0, z);
    } else if (coords.z == 3) {
        // Negative Y
        const float x = mix(-1.0, 1.0, uv.x);
        const float z = mix(1.0, -1.0, uv.y);
        dir = vec3(x, -1.0, z);
    } else if (coords.z == 4) {
        // Positive Z
        const float x = mix(-1.0, 1.0, uv.x);
        const float y = mix(1.0, -1.0, uv.y);
        dir = vec3(x, y, 1.0);
    } else {
        // Negative Z
        const float x = mix(1.0, -1.0, uv.x);
        const float y = mix(1.0, -1.0, uv.y);
        dir = vec3(x, y, -1.0);
    }

    return normalize(dir);
}

float SanitizeValue(float value)
{
    if (isnan(value) || isinf(value)) {
        return 0;
    }
    return value;
}

vec3 SanitizeChannels(vec3 value)
{
    return vec3(SanitizeValue(value.r),
                SanitizeValue(value.g),
                SanitizeValue(value.b));
}

// compute world position from texture coords
vec3 GetWorldPos(vec2 textureCoord)
{
    // have theta range from [-PI, PI] so the origin is in the center
    // of the image
    float theta = (textureCoord.x * 2.0 * PI) - PI;
    float phi = (textureCoord.y * PI);
    float x = cos(theta) * sin(phi);
    float y = cos(phi);
    float z = sin(theta) * sin(phi);
    return vec3(x, y, z);
}

--- --------------------------------------------------------------------------
-- glsl DomeLight.CommonSampling

float RadicalInverse(uint a)
{
    return float(bitfieldReverse(a)) * 2.3283064365386963e-10; // 0x1p-32
}

vec2 Hammersley2d(uint a, uint N)
{
    return vec2(float(a) / float(N), RadicalInverse(a));
}

vec3 ImportanceSample_GGX(vec2 Xi, float roughness, vec3 normal)
{
    // Maps a 2D point to a hemisphere with spread based on roughness
    float alpha = roughness * roughness;
    float phi = 2.0 * PI * Xi.x;
    
    // Clamp cosTheta to at most 1. Values larger than 1 (arising from floating 
    // point imprecision perhaps) can cause NaNs in the sinTheta term.
    float cosTheta = min(
        1.0, sqrt((1.0 - Xi.y) / (1.0 + (alpha*alpha - 1.0) * Xi.y)));
    
    float sinTheta = sqrt(1.0 - cosTheta * cosTheta);
    vec3 H = vec3(sinTheta * cos(phi), sinTheta * sin(phi), cosTheta);

    // Tangent space
    vec3 up = abs(normal.z) < 0.999 ? vec3(0.0, 0.0, 1.0) : vec3(1.0, 0.0, 0.0);
    vec3 tangentX = normalize(cross(up, normal));
    vec3 tangentY = normalize(cross(normal, tangentX));

    // Convert to world Space
    return normalize(tangentX * H.x + tangentY * H.y + normal * H.z);
}

--- --------------------------------------------------------------------------
-- glsl DomeLight.Cubemap

void main(void)
{
    ivec3 outCoords = GetCubemapCoords();
    vec3 dir = GetCubemapVec(outCoords);
    vec2 coord2D = vec2((atan(dir.z, dir.x) + 0.5 * PI) / (2.0 * PI),
                        acos(dir.y) / PI);
    vec4 outColor = HgiTextureLod_inTexture(coord2D, 0);

    HgiSet_outTexture(outCoords, outColor);
}

--- --------------------------------------------------------------------------
-- glsl DomeLight.Irradiance

const float deltaPhi = (2.0f * float(PI)) / 180.0f;
const float deltaTheta = (0.5f * float(PI)) / 64.0f;

vec3 SampleEnvMap(vec3 sampleVec)
{
    // Sample from a mipmap level of the environment cubemap determined by the
    // size of the environment map and the number of samples we are taking.
    //
    // Since inDims will be the dimensions of one cubemap face, we need to
    // multiply inDims.x by 4 to get the correct number of horizontal pixels.
    // We further offset the mip level by adding 2 to the logarithm result
    // to mitigate artifacts that arise with this convolution approach.
    ivec2 inDims = HgiGetSize_inTexture();
    float mipLevel = ceil(log2(4.0f * inDims.x * deltaPhi/(2.0 * PI)) + 2.0f);

    vec3 color = HgiTextureLod_inTexture(sampleVec, mipLevel).rgb;
    return SanitizeChannels(color);
}

vec3 ComputeIrradiance(vec3 inPos)
{
    vec3 N = inPos;
    // Depending on the cubemap face we are computing an irradiance value for,
    // we want to ensure we pick an up vector sufficiently distinct from the
    // N vector to avoid taking the cross product of nearly parallel vectors.
    // So the +X, -X, +Z, and -Z faces use the +Y-axis as the up vector, and the
    // +Y and -Y faces use the +Z-axis as the up vector.
    const int face = GetCubemapCoords().z;
    vec3 up = face == 2 || face == 3 ? vec3(0.0, 0.0, 1.0)
                                     : vec3(0.0, 1.0, 0.0);
    vec3 right = normalize(cross(up, N));
    up = cross(N, right);

    const float TWO_PI = PI * 2.0;
    const float HALF_PI = PI * 0.5;

    vec3 color = vec3(0.0);
    uint sampleCount = 0u;
    for (float phi = 0.0; phi < TWO_PI; phi += deltaPhi) {
        for (float theta = 0.0; theta < HALF_PI; theta += deltaTheta) {
            vec3 tempVec = cos(phi) * right + sin(phi) * up;
            vec3 sampleVector = cos(theta) * N + sin(theta) * tempVec;
            color += SampleEnvMap(sampleVector).rgb * cos(theta) * sin(theta);
            sampleCount++;
        }
    }
    return PI * color / float(sampleCount);
}

void main(void)
{
    ivec3 outCoords = GetCubemapCoords();
    vec3 dir = GetCubemapVec(outCoords);
    vec4 outColor = vec4(ComputeIrradiance(dir), 1.0);

    HgiSet_outTexture(outCoords, outColor);
}

--- --------------------------------------------------------------------------
-- glsl DomeLight.Prefilter

// Normal Distribution function
float Distribution_GGX(float dotNH, float roughness)
{
    float alpha = roughness * roughness;
    float alpha2 = alpha * alpha;
    float denom = dotNH * dotNH * (alpha2 - 1.0) + 1.0;
    return (alpha2)/(PI * denom*denom);
}

vec3 PrefilterEnvMap(vec3 R, float roughness)
{
    vec3 N = R;
    vec3 V = R;
    vec3 color = vec3(0.0);
    float totalWeight = 0.0;
    float envMapDim = float(HgiGetSize_inTexture().x);
    const uint numSamples = 1024u;
    for (uint i = 0u; i < numSamples; i++) {
        vec2 Xi = Hammersley2d(i, numSamples);
        vec3 H = ImportanceSample_GGX(Xi, roughness, N);
        vec3 L = 2.0 * dot(V, H) * H - V;
        float dotNL = clamp(dot(N, L), 0.0, 1.0);
        if (dotNL > 0.0) {

            float dotNH = clamp(dot(N, H), 0.0, 1.0);
            float dotVH = clamp(dot(V, H), 0.0, 1.0);

            // Probability Distribution Function
            float pdf = Distribution_GGX(dotNH, roughness) * dotNH
                                                / (4.0 * dotVH) + 0.0001;
            // Solid angle of current sample
            float omegaS = 1.0 / (float(numSamples) * pdf);
            // Solid angle of 1 pixel across all cube faces
            float omegaP = 4.0 * PI / (6.0 * envMapDim * envMapDim);
            // Biased (+1.0) mip level for better result
            float mipLevel = roughness == 0.0
                           ? 0.0 : max(0.5 * log2(omegaS / omegaP) + 1.0, 0.0f);
            vec3 value = HgiTextureLod_inTexture(L, mipLevel).rgb;
            color += SanitizeChannels(value) * dotNL;
            totalWeight += dotNL;

        }
    }
    return (color / totalWeight);
}

void main(void)
{
    ivec3 outCoords = GetCubemapCoords();
    vec3 R = GetCubemapVec(outCoords);
    vec4 outColor = vec4(PrefilterEnvMap(R, inRoughness), 1.0);

    HgiSet_outTexture(outCoords, outColor);
}

--- --------------------------------------------------------------------------
-- glsl DomeLight.BRDF

float Geometry_SchlicksmithGGX(float dotNL, float dotNV, float roughness)
{
    float k = (roughness * roughness) / 2.0;
    float GL = dotNL / (dotNL * (1.0 - k) + k);
    float GV = dotNV / (dotNV * (1.0 - k) + k);
    return GL * GV;
}

vec2 ComputeBRDF(float NoV, float roughness)
{
    // make sure NoV doesn't go exactly to 0 to avoid NaN
    NoV = max(NoV, 0.001);

    // Normal always points along z-axis for the 2D lookup
    const vec3 N = vec3(0.0, 0.0, 1.0);
    vec3 V = vec3(sqrt(1.0 - NoV*NoV), 0.0, NoV);

    vec2 LUT = vec2(0.0);
    const uint NUM_SAMPLES = 1024u;
    for (uint i = 0u; i < NUM_SAMPLES; i++) {
        vec2 Xi = Hammersley2d(i, NUM_SAMPLES);
        vec3 H = ImportanceSample_GGX(Xi, roughness, N);
        vec3 L = 2.0 * dot(V, H) * H - V;

        float dotNL = max(dot(N, L), 0.0);
        float dotNV = max(dot(N, V), 0.0);
        float dotVH = max(dot(V, H), 0.0);
        float dotNH = max(dot(H, N), 0.0);

        if (dotNL > 0.0) {
            float G = Geometry_SchlicksmithGGX(dotNL, dotNV, roughness);
            float G_Vis = (G * dotVH) / (dotNH * dotNV);
            float Fc = pow(1.0 - dotVH, 5.0);
            LUT += vec2((1.0 - Fc) * G_Vis, Fc * G_Vis);
        }
    }
    return LUT / float(NUM_SAMPLES);
}

void main(void)
{
    ivec2 outCoords = ivec2(hd_GlobalInvocationID.xy);

    vec2 texCoords = GetTexCoords(outCoords);
    // texCoords.x represents N dot E and texCoords.y represents roughness
    vec4 outColor = vec4(ComputeBRDF(texCoords.x, texCoords.y), 0.0, 1.0);

    HgiSet_outTexture(outCoords, outColor);
}